import streamlit as st
import google.generativeai as genai
from groq import Groq
from PIL import Image
import io
import base64
import requests
import fitz
import pandas as pd
from docx import Document
from pptx import Presentation

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ±Ù…ÙŠØ² ÙˆØ§Ù„ØµÙØ­Ø© ---
# Ù†Ø¶Ù…Ù† Ø£Ù† Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙŠØªÙ… Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡Ø§ ÙƒÙ€ UTF-8
import sys
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

st.set_page_config(page_title="AI Architect Multi-Pro", page_icon="ğŸš€", layout="wide")

# --- 2. ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ù„Ù€ Groq ---
def encode_image_to_base64(image):
    buffered = io.BytesIO()
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ RGB Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ JPEG
    if image.mode in ("RGBA", "P"):
        image = image.convert("RGB")
    image.save(buffered, format="JPEG")
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø·ÙˆØ± (ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ùˆ Groq Vision) ---
def generate_ai_response(provider, api_key, model_name, text_query, images=None):
    try:
        if provider == "Google Gemini":
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)
            payload = [text_query] + (images if images else [])
            response = model.generate_content(payload)
            return response.text
        
        elif provider == "Groq (Ultra Fast)":
            client = Groq(api_key=api_key)
            messages = []
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø±Ø¤ÙŠØ© (Vision) ÙˆÙÙŠÙ‡ ØµÙˆØ± Ù…Ø±ÙÙˆØ¹Ø©
            if "vision" in model_name.lower() and images:
                base64_image = encode_image_to_base64(images[0])
                messages = [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": text_query},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                            }
                        ]
                    }
                ]
            else:
                # Ù…Ø­Ø§Ø¯Ø«Ø© Ù†ØµÙŠØ© Ø¹Ø§Ø¯ÙŠØ© (ØªØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨ØªØ±Ù…ÙŠØ² UTF-8 ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
                messages = [{"role": "user", "content": text_query}]

            chat_completion = client.chat.completions.create(
                messages=messages,
                model=model_name,
            )
            return chat_completion.choices[0].message.content
            
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ Ù…Ù† {provider}: {str(e)}")
        return None

# --- 4. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.markdown("<h2 style='color: #00d2ff;'>âš™ï¸ Provider Settings</h2>", unsafe_allow_html=True)
    provider = st.selectbox("Choose AI Provider:", ["Google Gemini", "Groq (Ultra Fast)"])
    api_key = st.text_input(f"Enter {provider} API Key:", type="password")
    
    if api_key:
        if provider == "Google Gemini":
            model_choice = st.selectbox("Model:", ["gemini-1.5-flash", "gemini-1.5-pro"])
        else:
            # Ø¥Ø¶Ø§ÙØ© Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Groq Vision Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
            model_choice = st.selectbox("Model:", [
                "llama-3.2-11b-vision-preview",  # ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙˆØ±!
                "llama-3.1-70b-versatile", 
                "llama-3.1-8b-instant",
                "mixtral-8x7b-32768"
            ])

# --- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ---
if api_key:
    st.markdown("<h1 style='text-align: center;'>ğŸš€ AI Architect <span style='color: #00d2ff;'>Multi-Pro</span></h1>", unsafe_allow_html=True)
    
    tabs = st.tabs(["ğŸ“‘ Ultimate Analyzer", "ğŸ§  Universal Architect"])

    with tabs[0]:
        col1, col2 = st.columns([1, 1.2])
        with col1:
            up_docs = st.file_uploader("Upload Files (Images, PDF, Text)", accept_multiple_files=True)
            query = st.text_area("What is your request? (ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)", placeholder="Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")
        
        if st.button("Execute Analysis ğŸš€"):
            if query:
                with st.spinner(f"Processing via {provider}..."):
                    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    images_list = []
                    text_context = query
                    
                    if up_docs:
                        for doc in up_docs:
                            ext = doc.name.split('.')[-1].lower()
                            if ext in ['jpg', 'jpeg', 'png']:
                                images_list.append(Image.open(doc))
                            # (ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø¨Ø§Ù‚ÙŠ Ù…Ù†Ø·Ù‚ Ù…Ø¹Ø§Ù„Ø¬Ø© PDF/Office Ù‡Ù†Ø§ ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©)

                    res = generate_ai_response(provider, api_key, model_choice, text_context, images_list)
                    
                    if res:
                        st.session_state['res'] = res
                        with col2:
                            st.markdown("### ğŸ” Result:")
                            st.code(res, language="markdown")
            else:
                st.warning("Please enter a question first!")
else:
    st.info("ğŸ‘ˆ Please enter your API Key in the sidebar.")
